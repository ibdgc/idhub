# table-loader/services/data_transformer.py
import logging
from datetime import date, datetime
from typing import Any, Dict, List, Set, Union

import pandas as pd

logger = logging.getLogger(__name__)


class DataTransformer:
    """Transforms fragment data for database loading"""

    # System columns that should NEVER be loaded (auto-generated by DB)
    SYSTEM_COLUMNS: Set[str] = {
        "Id",
        "created_at",
        "updated_at",
    }

    # Table-specific default exclusions (fields that should ALWAYS be excluded)
    TABLE_DEFAULT_EXCLUSIONS = {
        "local_subject_ids": {
            "action",  # GSID resolution metadata, not a DB column
        },
    }

    def __init__(self, table_name: str, exclude_fields: Set[str] = None):
        """
        Initialize transformer

        Args:
            table_name: Target table name
            exclude_fields: Fields to exclude from loading (from validation report)
        """
        self.table_name = table_name

        # Start with system columns
        self.exclude_fields = self.SYSTEM_COLUMNS.copy()

        # Add table-specific defaults
        if table_name in self.TABLE_DEFAULT_EXCLUSIONS:
            self.exclude_fields.update(self.TABLE_DEFAULT_EXCLUSIONS[table_name])

        # Add fields from validation report
        if exclude_fields:
            self.exclude_fields.update(exclude_fields)

        logger.info(f"Excluding fields: {sorted(self.exclude_fields)}")

    def transform_records(
        self, data: Union[pd.DataFrame, Dict]
    ) -> List[Dict[str, Any]]:
        """
        Transform DataFrame or dict to list of records for database insertion

        Args:
            data: DataFrame or dict with 'records' key

        Returns:
            List of transformed records ready for database insertion
        """
        # Convert to DataFrame if needed
        if isinstance(data, dict):
            if "records" in data:
                df = pd.DataFrame(data["records"])
            else:
                df = pd.DataFrame([data])
        else:
            df = data

        if df.empty:
            logger.warning(f"No records to transform for {self.table_name}")
            return []

        # Get all columns from DataFrame
        all_columns = set(df.columns)

        # Determine which fields to keep (all columns except excluded ones)
        fields_to_keep = all_columns - self.exclude_fields

        logger.info(f"Fields to load for {self.table_name}: {sorted(fields_to_keep)}")

        # Convert DataFrame to list of dicts
        records = df.to_dict("records")

        # Transform each record
        transformed_records = []
        for record in records:
            # Type conversions and null handling
            transformed = self._transform_record(record)

            # Additional validation: skip records with invalid global_subject_id
            if "global_subject_id" in transformed:
                gsid = transformed.get("global_subject_id")

                # Check for various forms of invalid values
                if (
                    gsid is None
                    or gsid == ""
                    or pd.isna(gsid)
                    or str(gsid).lower() == "nan"
                ):
                    logger.warning(
                        f"Skipping record with invalid global_subject_id: {gsid}"
                    )
                    continue

            # Filter to only include fields we want to load
            filtered_record = {
                k: v for k, v in transformed.items() if k in fields_to_keep
            }
            transformed_records.append(filtered_record)

        logger.info(
            f"Transformed {len(transformed_records)} records for {self.table_name}"
        )

        return transformed_records

    def _transform_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """Transform a single record with type conversions"""
        transformed = {}

        for key, value in record.items():
            # Handle null values
            if pd.isna(value) or value == "" or value == "NULL" or value == "NA":
                transformed[key] = None
                continue

            # Type conversions based on value patterns
            transformed[key] = self._convert_value(value)

        return transformed

    def _convert_value(self, value: Any) -> Any:
        """Convert value to appropriate Python type"""
        if value is None or pd.isna(value):
            return None

        # Already correct type
        if isinstance(value, (int, float, bool, date, datetime)):
            return value

        # String conversions
        if isinstance(value, str):
            value = value.strip()

            # Empty string -> None
            if not value or value.upper() in ("NULL", "NA", "N/A"):
                return None

            # Boolean
            if value.lower() in ("true", "t", "yes", "y", "1"):
                return True
            if value.lower() in ("false", "f", "no", "n", "0"):
                return False

            # Try numeric
            try:
                if "." in value:
                    return float(value)
                return int(value)
            except ValueError:
                pass

            # Try date/datetime
            try:
                # ISO format datetime
                if "T" in value or " " in value:
                    return datetime.fromisoformat(value.replace("Z", "+00:00"))
                # ISO format date
                if "-" in value and len(value) == 10:
                    return datetime.strptime(value, "%Y-%m-%d").date()
            except (ValueError, AttributeError):
                pass

        # Return as-is
        return value
