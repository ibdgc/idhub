---
# .github/workflows/fragment-ingestion.yml
name: Fragment Ingestion Pipeline
on:
  workflow_dispatch:
    inputs:
      batch_id:
        description: Batch ID to load (e.g., batch_20251027_115323)
        required: true
        type: string
      dry_run:
        description: Dry run mode (preview changes without loading)
        required: false
        type: boolean
        default: true
jobs:
  validate:
    name: Validate Inputs
    runs-on: ubuntu-latest
    outputs:
      batch_id: ${{ steps.validate.outputs.batch_id }}
      mode: ${{ steps.validate.outputs.mode }}
    steps:
      - name: Validate batch ID format
        id: validate
        run: |
          BATCH_ID="${{ github.event.inputs.batch_id }}"
          if [[ ! "$BATCH_ID" =~ ^batch_[0-9]{8}_[0-9]{6}$ ]]; then
            echo "::error::Invalid batch_id format. Expected: batch_YYYYMMDD_HHMMSS"
            exit 1
          fi
          echo "batch_id=$BATCH_ID" >> $GITHUB_OUTPUT
          if [[ "${{ github.event.inputs.dry_run }}" == "true" ]]; then
            echo "mode=DRY RUN" >> $GITHUB_OUTPUT
            echo "::notice::Running in DRY RUN mode - no changes will be made"
          else
            echo "mode=LIVE LOAD" >> $GITHUB_OUTPUT
            echo "::warning::Running in LIVE mode - data will be loaded to database"
          fi
  ingest:
    name: Load Fragment Data
    needs: validate
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      - name: Set up SSH tunnel to database
        env:
          SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY }}
          SSH_HOST: ${{ secrets.SSH_HOST }}
          SSH_USER: ${{ secrets.SSH_USER }}
        run: |
          echo "::group::Setting up SSH tunnel"

          # Configure SSH
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H $SSH_HOST >> ~/.ssh/known_hosts

          # Start SSH tunnel
          ssh -4 -f -N \
            -o ServerAliveInterval=60 \
            -o ServerAliveCountMax=3 \
            -o ExitOnForwardFailure=yes \
            -L 127.0.0.1:5432:127.0.0.1:5432 \
            $SSH_USER@$SSH_HOST

          # Wait for tunnel to be ready
          echo "Waiting for tunnel..."
          for i in {1..30}; do
            if nc -zv 127.0.0.1 5432 2>&1 | grep -q succeeded; then
              echo "✓ SSH tunnel established successfully"
              echo "::endgroup::"
              exit 0
            fi
            echo "Attempt $i/30..."
            sleep 2
          done
          echo "::error::Failed to establish SSH tunnel"
          echo "::endgroup::"
          exit 1
      - name: Verify database connectivity
        env:
          PGPASSWORD: ${{ secrets.DB_PASSWORD }}
        run: |
          echo "::group::Testing database connection"

          # Install PostgreSQL client
          sudo apt-get update -qq
          sudo apt-get install -y postgresql-client

          # Test connection
          psql -h localhost -p 5432 -U idhub_user -d idhub -c "SELECT version();"
          echo "✓ Database connection verified"
          echo "::endgroup::"
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip
          cache-dependency-path: table-loader/requirements.txt
      - name: Install dependencies
        run: |
          echo "::group::Installing Python dependencies"
          cd table-loader
          pip install --upgrade pip
          pip install -r requirements.txt

          # Verify installation
          pip list | grep -E "(pandas|psycopg2|boto3)"
          echo "✓ Dependencies installed"
          echo "::endgroup::"
      - name: Create necessary directories
        run: |
          mkdir -p table-loader/logs
      - name: Verify S3 access to batch
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          S3_BUCKET: idhub-curated-fragments
        run: |
          echo "::group::Verifying S3 batch exists"
          pip install awscli
          BATCH_ID="${{ github.event.inputs.batch_id }}"

          # Updated to match actual S3 structure
          PREFIX="staging/validated/${BATCH_ID}/"
          echo "Searching for batch at: s3://$S3_BUCKET/$PREFIX"
          echo ""

          # List fragments in the batch
          if aws s3 ls "s3://$S3_BUCKET/$PREFIX" 2>/dev/null; then
            echo ""
            echo "✓ Found batch: $BATCH_ID"
            
            # Count fragments
            FRAGMENT_COUNT=$(aws s3 ls "s3://$S3_BUCKET/$PREFIX" | grep -c '.json' || echo "0")
            echo "Total fragments: $FRAGMENT_COUNT"
            
            if [ "$FRAGMENT_COUNT" -eq "0" ]; then
              echo "::error::No JSON fragments found in batch"
              exit 1
            fi
          else
            echo "::error::Batch not found: $BATCH_ID"
            echo ""
            echo "Available batches in staging/validated/:"
            aws s3 ls "s3://$S3_BUCKET/staging/validated/" || echo "Cannot list staging/validated/"
            exit 1
          fi
          echo "::endgroup::"
      - name: Run table loader (${{ needs.validate.outputs.mode }})
        id: load
        env:
          DB_HOST: localhost
          DB_NAME: idhub
          DB_USER: idhub_user
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_PORT: 5432
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-1
          S3_BUCKET: idhub-curated-fragments
        run: |
          echo "::group::Running table loader"
          cd table-loader

          # Build command
          CMD="python main.py --batch-id ${{ github.event.inputs.batch_id }}"
          if [[ "${{ github.event.inputs.dry_run }}" == "false" ]]; then
            CMD="$CMD --approve"
          fi
          echo "Executing: $CMD"
          echo ""

          # Run with output capture
          if $CMD 2>&1 | tee loader_output.log; then
            echo "::notice::✓ Table loader completed successfully"
            EXIT_CODE=0
          else
            echo "::error::✗ Table loader failed"
            EXIT_CODE=1
          fi
          echo "::endgroup::"
          exit $EXIT_CODE
      - name: Extract load summary
        if: always()
        run: |
          if [ -f table-loader/loader_output.log ]; then
            echo "::group::Load Summary"
            
            # Extract key metrics from logs
            grep -E "(Loaded|Processing|Error|Success|Failed)" table-loader/loader_output.log || true
            
            # Count operations
            RECORDS=$(grep -oP "Loaded \K\d+" table-loader/loader_output.log | tail -1 || echo "0")
            echo "Records processed: $RECORDS"
            
            echo "::endgroup::"
          fi
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: loader-logs-${{ github.event.inputs.batch_id }}
          path: |
            table-loader/logs/
            table-loader/loader_output.log
          retention-days: 30
          if-no-files-found: warn
      - name: Upload load report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: load-report-${{ github.event.inputs.batch_id }}
          path: table-loader/loader_output.log
          retention-days: 90
      - name: Cleanup SSH tunnel
        if: always()
        run: |
          pkill -f "ssh.*127.0.0.1:5432" || true
          echo "✓ SSH tunnel closed"
      - name: Notify on failure
        if: failure() && github.event.inputs.dry_run == 'false'
        run: |
          echo "::error::Fragment ingestion failed for batch ${{ github.event.inputs.batch_id }}"
          echo "Check the uploaded logs for details"
      - name: Summary
        if: always()
        run: |-
          echo "## Fragment Ingestion Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Batch ID**: \`${{ github.event.inputs.batch_id }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Mode**: ${{ needs.validate.outputs.mode }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by**: @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f table-loader/loader_output.log ]; then
            echo "### Load Details" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            tail -20 table-loader/loader_output.log >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
